# Parallelize Independent Evaluation Stages

**Overall Progress:** `100%` Â· **Status:** Complete

## TLDR
Run the 6 independent data-collection stages (walk_scores, neighborhood, schools, urban_access, transit_access, green_escape) concurrently after geocode completes, using `concurrent.futures.ThreadPoolExecutor`. Tier 1 checks and Tier 2 scoring remain sequential. Target: ~25â€“35s wall-clock (down from 60â€“90s).

## Critical Decisions

- **ThreadPoolExecutor over asyncio**: All stages are I/O-bound HTTP calls. Threads are the right primitive â€” no need to rewrite call sites to async. Each stage already uses `requests.Session` which releases the GIL during I/O.
- **Batch A only (data collection)**: Tier 2 scoring stays sequential. Dependencies are tangled (score_park_access needs green_escape, score_third_place needs neighborhood, etc.). Parallelizing Tier 2 risks silent scoring bugs. Can revisit in a follow-up.
- **nc_trace is thread-local â€” must propagate explicitly**: `get_trace()` uses `threading.local()` (nc_trace.py:244). Child threads won't see the parent's TraceContext. Fix: call `set_trace(parent_ctx)` at the start of each thread worker. The TraceContext lists (`.api_calls`, `.stages`) will receive concurrent appends â€” Python list `.append()` is GIL-atomic, so this is safe without a lock.
- **Single combined on_stage call for parallel batch**: Fire `on_stage("analyzing")` once before the parallel batch. Individual stages don't call `on_stage` during parallel execution (they still call `_timed_stage` for trace recording). After the batch, resume sequential `on_stage` calls for tier1_checks and scoring stages.
- **green_space._cache needs a lock**: Module-level `_cache` dict in green_space.py gets concurrent reads/writes from parallel stages (green_escape + potentially neighborhood). Add a `threading.Lock` around `_cached_get`/`_cached_set`.
- **UrbanAccessEngine._cache needs a lock**: Class-level `_cache` dict gets concurrent reads/writes. Add a `threading.Lock` around cache access in `_get_duration`.
- **GoogleMapsClient.session is per-instance**: Each `GoogleMapsClient` created in `evaluate_property()` has its own `requests.Session`. `requests.Session` is **not** thread-safe. Fix: create a separate `GoogleMapsClient` per thread, or use `requests.get()` directly (no session reuse). Simplest: instantiate a new `GoogleMapsClient(api_key)` inside each thread's wrapper function.
- **OverpassClient.session is per-instance**: Same concern. green_space.py already creates a local `requests.Session()` per Overpass call (line 458), so it's already safe. The `OverpassClient` in property_evaluator.py is only used for tier1_checks (sequential) â€” no change needed.

## Tasks

- [x] ðŸŸ© **Step 1: Add thread-safe caching to green_space.py**
  - [x] ðŸŸ© Add a module-level `threading.Lock` (`_cache_lock`)
  - [x] ðŸŸ© Wrap `_cached_get()` and `_cached_set()` with the lock

- [x] ðŸŸ© **Step 2: Add thread-safe caching to urban_access.py**
  - [x] ðŸŸ© Add a class-level `threading.Lock` to `UrbanAccessEngine`
  - [x] ðŸŸ© Wrap `_cache` reads/writes in `_geocode_cached` and `_travel_time` with the lock

- [x] ðŸŸ© **Step 3: Parallelize Batch A in evaluate_property()**
  - [x] ðŸŸ© Add `from concurrent.futures import ThreadPoolExecutor, as_completed` import
  - [x] ðŸŸ© Add `from nc_trace import get_trace, set_trace` import (set_trace needed for thread propagation)
  - [x] ðŸŸ© Create `_threaded_stage` wrapper: propagates trace, creates fresh GoogleMapsClient, swaps maps arg, calls `_timed_stage`
  - [x] ðŸŸ© Create `_timed_stage_in_thread` helper for stages without a maps client (walk_scores)
  - [x] ðŸŸ© Replace 6 sequential try/except blocks with `ThreadPoolExecutor(max_workers=6)` block
  - [x] ðŸŸ© Submit each stage as a future; map futures to stage names
  - [x] ðŸŸ© Collect results via iteration; assign each to correct `result.*` field
  - [x] ðŸŸ© Individual try/except per `future.result()` (graceful degradation preserved)
  - [x] ðŸŸ© Fire `on_stage("analyzing")` once before the parallel batch

- [x] ðŸŸ© **Step 4: Handle walk_scores result assignment**
  - [x] ðŸŸ© Extracted `_assign_walk_scores()` helper for the multi-field unpacking

- [x] ðŸŸ© **Step 5: Handle schools conditional (ENABLE_SCHOOLS)**
  - [x] ðŸŸ© Schools future only submitted when `ENABLE_SCHOOLS` is True

- [x] ðŸŸ© **Step 6: Verify nc_trace cross-thread recording**
  - [x] ðŸŸ© `set_trace(parent_ctx)` in child threads â†’ `get_trace()` returns shared TraceContext âœ“
  - [x] ðŸŸ© `trace.record_api_call()` and `trace.record_stage()` append to shared lists â€” GIL-atomic âœ“
  - [x] ðŸŸ© `_current_stage` race accepted: parallel threads overwrite the shared field, so per-stage API attribution in trace may drift. Total counts remain correct. Trace is debugging-only â€” acceptable trade-off per plan decision.

- [x] ðŸŸ© **Step 7: Verify no changes to Tier 1, Tier 2, Tier 3**
  - [x] ðŸŸ© Tier 1 checks remain sequential after the parallel batch (unchanged)
  - [x] ðŸŸ© Tier 2 scoring remains sequential (unchanged)
  - [x] ðŸŸ© Tier 3 bonuses remain sequential (unchanged)
  - [x] ðŸŸ© No scoring logic or API patterns changed

- [x] ðŸŸ© **Step 8: Test with existing test suite**
  - [x] ðŸŸ© 59/59 core tests pass (green_space, transit_access, urban_access) â€” zero regressions
  - [x] ðŸŸ© All imports resolve correctly; locks instantiated as expected
  - [x] ðŸŸ© Pre-existing failures (Flask not installed, hardcoded path) unrelated to changes
